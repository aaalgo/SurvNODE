{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from lifelines import CoxPHFitter\n",
    "from lifelines import KaplanMeierFitter\n",
    "\n",
    "from pycox.evaluation import EvalSurv\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "random_seed = 137\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping class from https://github.com/Bjarten/early-stopping-pytorch\n",
    "from SurvNODE.EarlyStopping import EarlyStopping\n",
    "from SurvNODE.SurvNODE_x_ranking import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measures(odesurv,initial,x,Tstart,Tstop,From,To,trans,status, multiplier=1.,points=500):\n",
    "    with torch.no_grad():\n",
    "        time_grid = np.linspace(0, multiplier, points)\n",
    "        pvec = torch.zeros((points,x.shape[0]))\n",
    "        surv_ode = odesurv.predict(x,torch.from_numpy(np.linspace(0,multiplier,points)).float().to(x.device))\n",
    "        pvec = torch.einsum(\"ilkj,k->ilj\",(surv_ode[:,:,:,:],initial))[:,:,0].cpu()\n",
    "        pvec = np.array(pvec.cpu().detach())\n",
    "        surv_ode_df = pd.DataFrame(pvec)\n",
    "        surv_ode_df.loc[:,\"time\"] = np.linspace(0,multiplier,points)\n",
    "        surv_ode_df = surv_ode_df.set_index([\"time\"])\n",
    "        ev_ode = EvalSurv(surv_ode_df, np.array(Tstop.cpu()), np.array(status.cpu()), censor_surv='km')\n",
    "        conc = ev_ode.concordance_td('antolini')\n",
    "        ibs = ev_ode.integrated_brier_score(time_grid)\n",
    "        inbll = ev_ode.integrated_nbll(time_grid)\n",
    "    return conc,ibs,inbll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_pandas import DataFrameMapper\n",
    "import pandas as pd\n",
    "\n",
    "def make_dataloader(df,Tmax,batchsize):\n",
    "#     cols_standardize = ['x0', 'x7', 'x8', 'x9', 'x10', 'x11', 'x12', 'x13']\n",
    "#     cols_leave = ['x1', 'x2', 'x3', 'x4', 'x5', 'x6']\n",
    "\n",
    "#     standardize = [([col], StandardScaler()) for col in cols_standardize]\n",
    "#     leave = [(col, None) for col in cols_leave]\n",
    "#     x_mapper = DataFrameMapper(standardize + leave)\n",
    "#     X = x_mapper.fit_transform(df).astype('float32')\n",
    "\n",
    "    X = df[['x0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8']].values\n",
    "    \n",
    "    X = torch.from_numpy(X).float().to(device)\n",
    "    T = torch.from_numpy(df[[\"duration\"]].values).float().flatten().to(device)\n",
    "    T = T/Tmax\n",
    "    T[T==0] = 1e-8\n",
    "    E = torch.from_numpy(df[[\"event\"]].values).float().flatten().to(device)\n",
    "\n",
    "    Tstart = torch.from_numpy(np.array([0 for i in range(T.shape[0])])).float().to(device)\n",
    "    From = torch.tensor([1],device=device).repeat((T.shape))\n",
    "    To = torch.tensor([2],device=device).repeat((T.shape))\n",
    "    trans = torch.tensor([1],device=device).repeat((T.shape))\n",
    "\n",
    "    dataset = TensorDataset(X,Tstart,T,From,To,trans,E)\n",
    "    loader = DataLoader(dataset, batch_size=batchsize, shuffle=True)\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def odesurv_manual_benchmark(df_train, df_test,config,name):\n",
    "    torch.cuda.empty_cache()\n",
    "    df_train, df_val = train_test_split(df_train, test_size=0.2, stratify=df_train.loc[:,\"event\"])\n",
    "    \n",
    "    Tmax = df_train[\"duration\"].max()\n",
    "    \n",
    "    train_loader = make_dataloader(df_train,Tmax/config[\"multiplier\"],int(len(df_train)*config[\"batch_size\"]))\n",
    "    val_loader = make_dataloader(df_val,Tmax/config[\"multiplier\"],len(df_val))\n",
    "    test_loader = make_dataloader(df_test,Tmax/config[\"multiplier\"],len(df_test))\n",
    "    \n",
    "    num_in = 9\n",
    "    num_latent = config[\"num_latent\"]\n",
    "    layers_encoder =  [config[\"encoder_neurons\"]]*config[\"num_encoder_layers\"]\n",
    "    dropout_encoder = [config[\"encoder_dropout\"]]*config[\"num_encoder_layers\"]\n",
    "    layers_odefunc =  [config[\"odefunc_neurons\"]]*config[\"num_odefunc_layers\"]\n",
    "\n",
    "    trans_matrix = torch.tensor([[np.nan,1],[np.nan,np.nan]]).to(device)\n",
    "\n",
    "    encoder = Encoder(num_in,num_latent,layers_encoder, dropout_encoder).to(device)\n",
    "    odefunc = ODEFunc(trans_matrix,num_in,num_latent,layers_odefunc,config[\"softplus_beta\"]).to(device)\n",
    "    block = ODEBlock(odefunc).to(device)\n",
    "    odesurv = SurvNODE(block,encoder).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(odesurv.parameters(), weight_decay = config[\"weight_decay\"], lr=config[\"lr\"])\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=config[\"scheduler_gamma\"], patience=config[\"scheduler_epoch\"])\n",
    "\n",
    "    early_stopping = EarlyStopping(name=name,patience=config[\"patience\"], verbose=True)\n",
    "    for i in tqdm(range(1000)):\n",
    "        odesurv.train()\n",
    "        for mini,ds in enumerate(train_loader):\n",
    "            myloss,_,_ = loss(odesurv,*ds,mu=config[\"mu\"],alpha=config[\"alpha\"],sigma=config[\"sigma\"])\n",
    "            optimizer.zero_grad()\n",
    "            myloss.backward()    \n",
    "            optimizer.step()\n",
    "\n",
    "        \n",
    "        odesurv.eval()\n",
    "        with torch.no_grad():\n",
    "            lossval,conc,ibs,ibnll = 0., 0., 0., 0.\n",
    "            for _,ds in enumerate(val_loader):\n",
    "                t1,_,_ = loss(odesurv,*ds,mu=config[\"mu\"],alpha=config[\"alpha\"],sigma=config[\"sigma\"])\n",
    "                lossval += t1.item()\n",
    "                t1,t2,t3 = measures(odesurv,torch.tensor([1.,0.],device=device),*ds,multiplier=config[\"multiplier\"])\n",
    "                conc += t1\n",
    "                ibs += t2\n",
    "                ibnll += t3\n",
    "            early_stopping(lossval/len(val_loader), odesurv)\n",
    "            scheduler.step(lossval/len(val_loader))\n",
    "            \n",
    "            conc_test,ibs_test,ibnll_test = 0., 0., 0.\n",
    "            print(\"it: \"+str(i)+\", train loss=\"+str(myloss.item())+\", validation loss=\"+str(lossval/len(val_loader))+\", c=\"+str(conc/len(val_loader))+\", ibs=\"+str(ibs/len(val_loader))+\", ibnll=\"+str(ibnll/len(val_loader)))\n",
    "\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    odesurv.load_state_dict(torch.load(name+'_checkpoint.pt'))\n",
    "\n",
    "    odesurv.eval()\n",
    "    with torch.no_grad():\n",
    "        conc,ibs,ibnll = 0., 0., 0.\n",
    "        for _,ds in enumerate(test_loader):\n",
    "            t1,t2,t3 = measures(odesurv,torch.tensor([1.,0.],device=device),*ds,multiplier=config[\"multiplier\"])\n",
    "            conc += t1\n",
    "            ibs += t2\n",
    "            ibnll += t3\n",
    "    return conc/len(test_loader), ibs/len(test_loader), ibnll/len(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3459ad50211412984a15dd17ee383f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss decreased (inf --> 0.161452).  Saving model ...\n",
      "it: 0, train loss=0.7617104649543762, validation loss=0.16145195066928864, c=0.5354734029015017, ibs=0.181363949950862, ibnll=0.5383163511823669\n",
      "EarlyStopping counter: 1 out of 20\n",
      "it: 1, train loss=0.5374631881713867, validation loss=0.24406588077545166, c=0.5509671672181217, ibs=0.18134758631652412, ibnll=0.5395845425523068\n",
      "EarlyStopping counter: 2 out of 20\n",
      "it: 2, train loss=0.39296647906303406, validation loss=0.3268198072910309, c=0.5474357342835328, ibs=0.18127056306803127, ibnll=0.5390520197884567\n",
      "EarlyStopping counter: 3 out of 20\n",
      "it: 3, train loss=0.16378892958164215, validation loss=0.207983136177063, c=0.5682425553575974, ibs=0.18010064108857227, ibnll=0.5366584958962884\n",
      "EarlyStopping counter: 4 out of 20\n",
      "it: 4, train loss=0.19430136680603027, validation loss=0.1715567409992218, c=0.5686243318910664, ibs=0.18165707215164492, ibnll=0.5396820362383445\n",
      "EarlyStopping counter: 5 out of 20\n",
      "it: 5, train loss=0.17162925004959106, validation loss=0.1675759255886078, c=0.5698014762025961, ibs=0.18023890833198036, ibnll=0.536866775132894\n",
      "Validation loss decreased (0.161452 --> 0.159683).  Saving model ...\n",
      "it: 6, train loss=0.15832427144050598, validation loss=0.15968257188796997, c=0.5706604734029015, ibs=0.18474682364499218, ibnll=0.5478526976890609\n",
      "Validation loss decreased (0.159683 --> 0.146040).  Saving model ...\n",
      "it: 7, train loss=0.13700510561466217, validation loss=0.14604026079177856, c=0.5687515907355561, ibs=0.1799190561923658, ibnll=0.5355491862108571\n",
      "EarlyStopping counter: 1 out of 20\n",
      "it: 8, train loss=0.13412334024906158, validation loss=0.15207907557487488, c=0.5689742937134131, ibs=0.18409161294935708, ibnll=0.5440132569780294\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from pycox import datasets\n",
    "\n",
    "kfold = StratifiedKFold(5, shuffle=True)\n",
    "df_all = datasets.metabric.read_df()\n",
    "gen = kfold.split(df_all.iloc[:,df_all.columns.values!=\"event\"],df_all.loc[:,\"event\"])\n",
    "\n",
    "config = {\n",
    "    \"lr\": 1e-3,\n",
    "    \"weight_decay\": 1e-3,\n",
    "    \"num_latent\": 200,\n",
    "    \"encoder_neurons\": 50,\n",
    "    \"num_encoder_layers\": 4,\n",
    "    \"encoder_dropout\": 0.,\n",
    "    \"odefunc_neurons\": 800,\n",
    "    \"num_odefunc_layers\": 2,\n",
    "    \"batch_size\": 1/3,\n",
    "    \"multiplier\": 1.,\n",
    "    \"mu\": 1e-1,\n",
    "    \"alpha\": 0.7,\n",
    "    \"sigma\": 0.1,\n",
    "    \"softplus_beta\": 1.,\n",
    "    \"scheduler_epoch\": 10,\n",
    "    \"scheduler_gamma\": 0.1,\n",
    "    \"patience\": 20\n",
    "}\n",
    "\n",
    "odesurv_bench_vals = []\n",
    "for g in gen:\n",
    "    df_train = df_all.iloc[g[0]]\n",
    "    df_test =  df_all.iloc[g[1]]\n",
    "    conc, ibs, ibnll = odesurv_manual_benchmark(df_train,df_test,config,\"metabric_test\")\n",
    "    odesurv_bench_vals.append([conc,ibs,ibnll])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"c=\"+str(np.mean(np.array(odesurv_bench_vals)[:,0]))+\"+-\"+str(np.std(np.array(odesurv_bench_vals)[:,0])))\n",
    "print(\"ibs=\"+str(np.mean(np.array(odesurv_bench_vals)[:,1]))+\"+-\"+str(np.std(np.array(odesurv_bench_vals)[:,1])))\n",
    "print(\"ibnll=\"+str(np.mean(np.array(odesurv_bench_vals)[:,2]))+\"+-\"+str(np.std(np.array(odesurv_bench_vals)[:,2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-6.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-6:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
